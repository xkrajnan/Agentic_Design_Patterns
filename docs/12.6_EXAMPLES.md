# Complete Code Examples

**Part of**: [Python Architecture for Aerospace Reliability](12.0_OVERVIEW.md)

---

## TL;DR

This document contains complete, runnable code examples for all patterns and components. Examples are organized by:
1. **Core Types** - Complete type definitions
2. **Detection Strategies** - All detector implementations
3. **Isolation Strategies** - Circuit breaker, bulkhead, hierarchical
4. **Recovery Strategies** - Retry, fallback, degradation, safe mode
5. **High-Level Patterns** - FDIR, TMR, HealthMonitor
6. **End-to-End Workflows** - Complete application examples

---

## I. Core Types

### 1.1 Complete Type Definitions

```python
"""Core type definitions for aerospace reliability patterns."""

from enum import Enum, auto
from dataclasses import dataclass, field
from typing import Any, Optional, Dict
from datetime import datetime


class HealthState(Enum):
    """Agent health state from FDIR state machine."""
    HEALTHY = auto()
    DEGRADED = auto()
    FAILED = auto()
    ISOLATED = auto()


class FailureType(Enum):
    """Failure classification taxonomy."""
    TIMEOUT = auto()
    EXCEPTION = auto()
    INVALID_OUTPUT = auto()
    RATE_LIMIT = auto()
    UNAVAILABLE = auto()
    VALIDATION_FAILED = auto()
    ANOMALY_DETECTED = auto()


class FaultToleranceStrategy(Enum):
    """Dâ‚… dimension values from extended 5D design space."""
    NONE = auto()
    RETRY = auto()
    REDUNDANT = auto()
    FDIR = auto()


class CircuitState(Enum):
    """Circuit breaker states."""
    CLOSED = auto()
    OPEN = auto()
    HALF_OPEN = auto()


class RecoveryLevel(Enum):
    """Recovery escalation levels."""
    L0_RETRY = auto()
    L1_FALLBACK = auto()
    L2_DEGRADATION = auto()
    L3_SAFE_MODE = auto()


@dataclass(frozen=True)
class FailureEvent:
    """Immutable failure event record."""
    failure_type: FailureType
    timestamp: datetime
    agent_id: str
    message: str
    context: Optional[Dict[str, Any]] = None
    exception: Optional[Exception] = None


@dataclass
class DetectionResult:
    """Result from fault detection phase."""
    is_healthy: bool
    confidence: float
    failure_type: Optional[FailureType] = None
    evidence: Optional[Dict[str, Any]] = None
    severity: float = 0.0


@dataclass
class RecoveryResult:
    """Result from recovery attempt."""
    success: bool
    level_used: RecoveryLevel
    result: Optional[Any] = None
    escalate: bool = False
    reason: Optional[str] = None


@dataclass
class IsolatedSubsystem:
    """Represents an isolated agent/subsystem."""
    agent_id: str
    failure_event: FailureEvent
    state_snapshot: Dict[str, Any]
    isolation_time: float = field(
        default_factory=lambda: datetime.now().timestamp()
    )
```

---

## II. Detection Strategy Implementations

### 2.1 TimeoutDetector

```python
"""Timeout-based fault detection."""

import time
from dataclasses import dataclass
from typing import Dict, Any


@dataclass
class TimeoutDetectorConfig:
    timeout_seconds: float = 30.0
    warning_threshold: float = 0.8


class TimeoutDetector:
    """Detects failures based on response time."""

    def __init__(self, config: TimeoutDetectorConfig = None):
        self.config = config or TimeoutDetectorConfig()
        self._start_time: float = 0.0

    @property
    def detection_type(self) -> str:
        return "timeout"

    def start_timer(self) -> None:
        self._start_time = time.monotonic()

    async def detect(
        self,
        observation: Dict[str, Any],
        context: 'ExecutionContext'
    ) -> DetectionResult:
        elapsed = observation.get(
            "elapsed",
            time.monotonic() - self._start_time
        )

        if elapsed > self.config.timeout_seconds:
            return DetectionResult(
                is_healthy=False,
                confidence=1.0,
                failure_type=FailureType.TIMEOUT,
                evidence={"elapsed": elapsed, "timeout": self.config.timeout_seconds},
                severity=1.0
            )

        warning_threshold = self.config.timeout_seconds * self.config.warning_threshold
        if elapsed > warning_threshold:
            return DetectionResult(
                is_healthy=True,
                confidence=0.7,
                severity=0.5,
                evidence={"elapsed": elapsed, "warning": True}
            )

        return DetectionResult(
            is_healthy=True,
            confidence=0.95,
            evidence={"elapsed": elapsed}
        )
```

### 2.2 StatisticalAnomalyDetector

```python
"""Statistical anomaly detection using z-score analysis."""

import statistics
from collections import deque
from dataclasses import dataclass, field
from typing import Dict, Any, List


@dataclass
class AnomalyDetectorConfig:
    zscore_threshold: float = 3.0
    window_size: int = 100
    min_samples: int = 10
    metrics: List[str] = field(default_factory=lambda: ["elapsed", "output_length"])


class StatisticalAnomalyDetector:
    """Detects anomalies using z-score analysis."""

    def __init__(self, config: AnomalyDetectorConfig = None):
        self.config = config or AnomalyDetectorConfig()
        self._history: Dict[str, deque] = {
            metric: deque(maxlen=self.config.window_size)
            for metric in self.config.metrics
        }

    @property
    def detection_type(self) -> str:
        return "anomaly"

    def _calculate_zscore(self, value: float, history: deque) -> float:
        if len(history) < self.config.min_samples:
            return 0.0

        mean = statistics.mean(history)
        std = statistics.stdev(history) if len(history) > 1 else 1.0

        if std == 0:
            return 0.0

        return (value - mean) / std

    async def detect(
        self,
        observation: Dict[str, Any],
        context: 'ExecutionContext'
    ) -> DetectionResult:
        anomalies = []
        max_zscore = 0.0

        for metric in self.config.metrics:
            if metric not in observation:
                continue

            value = observation[metric]
            if not isinstance(value, (int, float)):
                continue

            zscore = self._calculate_zscore(value, self._history[metric])
            self._history[metric].append(value)

            if abs(zscore) > self.config.zscore_threshold:
                anomalies.append({
                    "metric": metric,
                    "value": value,
                    "zscore": zscore
                })
                max_zscore = max(max_zscore, abs(zscore))

        if anomalies:
            return DetectionResult(
                is_healthy=False,
                confidence=min(1.0, max_zscore / 5.0),
                failure_type=FailureType.ANOMALY_DETECTED,
                evidence={"anomalies": anomalies},
                severity=min(1.0, max_zscore / 5.0)
            )

        return DetectionResult(
            is_healthy=True,
            confidence=0.9,
            evidence={"metrics_checked": self.config.metrics}
        )
```

### 2.3 CompositeDetector

```python
"""Composite detector combining multiple strategies."""

from typing import List, Dict, Any


class CompositeDetector:
    """Combines multiple detection strategies."""

    def __init__(
        self,
        strategies: List['DetectionStrategy'],
        fail_fast: bool = True
    ):
        self.strategies = strategies
        self.fail_fast = fail_fast

    @property
    def detection_type(self) -> str:
        types = [s.detection_type for s in self.strategies]
        return f"composite({','.join(types)})"

    async def detect(
        self,
        observation: Dict[str, Any],
        context: 'ExecutionContext'
    ) -> DetectionResult:
        results: List[DetectionResult] = []

        for strategy in self.strategies:
            result = await strategy.detect(observation, context)
            results.append(result)

            if self.fail_fast and not result.is_healthy:
                return result

        if not results:
            return DetectionResult(is_healthy=True, confidence=1.0)

        all_healthy = all(r.is_healthy for r in results)
        avg_confidence = sum(r.confidence for r in results) / len(results)
        worst = max(results, key=lambda r: r.severity)

        return DetectionResult(
            is_healthy=all_healthy,
            confidence=avg_confidence,
            failure_type=worst.failure_type if not all_healthy else None,
            severity=worst.severity,
            evidence={
                "sub_results": [
                    {"type": s.detection_type, "healthy": r.is_healthy}
                    for s, r in zip(self.strategies, results)
                ]
            }
        )
```

---

## III. Isolation Strategy Implementations

### 3.1 CircuitBreakerIsolation

```python
"""Circuit breaker isolation strategy."""

import asyncio
import time
from dataclasses import dataclass


@dataclass
class CircuitBreakerConfig:
    failure_threshold: int = 5
    recovery_timeout: float = 30.0
    half_open_max_calls: int = 1


class CircuitBreakerIsolation:
    """Circuit breaker pattern for fault isolation."""

    def __init__(self, config: CircuitBreakerConfig = None):
        self.config = config or CircuitBreakerConfig()
        self._state = CircuitState.CLOSED
        self._failure_count = 0
        self._last_failure_time = 0.0
        self._half_open_calls = 0
        self._lock = asyncio.Lock()

    @property
    def state(self) -> CircuitState:
        if self._state == CircuitState.OPEN:
            elapsed = time.monotonic() - self._last_failure_time
            if elapsed >= self.config.recovery_timeout:
                self._state = CircuitState.HALF_OPEN
                self._half_open_calls = 0
        return self._state

    @property
    def time_until_recovery(self) -> float:
        if self._state != CircuitState.OPEN:
            return 0.0
        elapsed = time.monotonic() - self._last_failure_time
        return max(0, self.config.recovery_timeout - elapsed)

    async def check_request_allowed(self) -> bool:
        async with self._lock:
            state = self.state

            if state == CircuitState.CLOSED:
                return True

            if state == CircuitState.OPEN:
                raise CircuitOpenError(
                    agent_id="circuit_breaker",
                    recovery_time=self.time_until_recovery
                )

            if state == CircuitState.HALF_OPEN:
                if self._half_open_calls < self.config.half_open_max_calls:
                    self._half_open_calls += 1
                    return True
                raise CircuitOpenError(
                    agent_id="circuit_breaker",
                    recovery_time=self.config.recovery_timeout
                )

        return False

    async def record_success(self) -> None:
        async with self._lock:
            self._failure_count = 0
            if self._state == CircuitState.HALF_OPEN:
                self._state = CircuitState.CLOSED

    async def record_failure(self) -> None:
        async with self._lock:
            self._failure_count += 1
            self._last_failure_time = time.monotonic()

            if self._state == CircuitState.HALF_OPEN:
                self._state = CircuitState.OPEN
            elif self._failure_count >= self.config.failure_threshold:
                self._state = CircuitState.OPEN

    async def isolate(
        self,
        failure_event: FailureEvent,
        agent: 'Agent',
        context: 'ExecutionContext'
    ) -> IsolatedSubsystem:
        await self.record_failure()
        return IsolatedSubsystem(
            agent_id=agent.name,
            failure_event=failure_event,
            state_snapshot=dict(context.session_state)
        )

    async def release(self, isolated: IsolatedSubsystem) -> None:
        await self.record_success()
```

### 3.2 BulkheadIsolation

```python
"""Bulkhead isolation using semaphores."""

import asyncio
from dataclasses import dataclass
from typing import Dict


@dataclass
class BulkheadConfig:
    max_concurrent: int = 10
    max_queue_size: int = 100
    timeout_seconds: float = 30.0
    name: str = "default"


class BulkheadIsolation:
    """Bulkhead pattern for resource isolation."""

    def __init__(self, config: BulkheadConfig = None):
        self.config = config or BulkheadConfig()
        self._semaphore = asyncio.Semaphore(self.config.max_concurrent)
        self._queue_count = 0
        self._active_count = 0
        self._rejected_count = 0
        self._lock = asyncio.Lock()

    @property
    def metrics(self) -> Dict[str, int]:
        return {
            "active": self._active_count,
            "queued": self._queue_count,
            "rejected": self._rejected_count
        }

    async def acquire(self) -> bool:
        async with self._lock:
            if self._queue_count >= self.config.max_queue_size:
                self._rejected_count += 1
                return False
            self._queue_count += 1

        try:
            acquired = await asyncio.wait_for(
                self._semaphore.acquire(),
                timeout=self.config.timeout_seconds
            )
            if acquired:
                async with self._lock:
                    self._queue_count -= 1
                    self._active_count += 1
                return True
        except asyncio.TimeoutError:
            async with self._lock:
                self._queue_count -= 1
                self._rejected_count += 1
            return False

        return False

    async def release(self) -> None:
        async with self._lock:
            self._active_count -= 1
        self._semaphore.release()

    async def __aenter__(self):
        if not await self.acquire():
            raise IsolationError(f"Bulkhead {self.config.name} rejected request")
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.release()
        return False
```

---

## IV. Recovery Strategy Implementations

### 4.1 RetryStrategy

```python
"""Retry with exponential backoff."""

import asyncio
import random
from dataclasses import dataclass, field
from typing import Tuple


@dataclass
class RetryConfig:
    max_retries: int = 3
    base_delay: float = 1.0
    max_delay: float = 60.0
    backoff_factor: float = 2.0
    jitter: float = 0.1
    retryable_failures: Tuple[FailureType, ...] = field(
        default_factory=lambda: (
            FailureType.TIMEOUT,
            FailureType.RATE_LIMIT,
            FailureType.UNAVAILABLE,
        )
    )


class RetryStrategy:
    """Retry with exponential backoff."""

    def __init__(self, config: RetryConfig = None):
        self.config = config or RetryConfig()

    @property
    def level(self) -> RecoveryLevel:
        return RecoveryLevel.L0_RETRY

    def can_handle(self, failure_type: FailureType) -> bool:
        return failure_type in self.config.retryable_failures

    def _calculate_delay(self, attempt: int) -> float:
        delay = min(
            self.config.base_delay * (self.config.backoff_factor ** attempt),
            self.config.max_delay
        )
        jitter_range = delay * self.config.jitter
        delay += random.uniform(-jitter_range, jitter_range)
        return max(0, delay)

    async def recover(
        self,
        failure_event: FailureEvent,
        agent: 'Agent',
        context: 'ExecutionContext'
    ) -> RecoveryResult:
        if not self.can_handle(failure_event.failure_type):
            return RecoveryResult(
                success=False,
                level_used=self.level,
                escalate=True,
                reason=f"Cannot handle {failure_event.failure_type}"
            )

        original_input = failure_event.context.get("input") if failure_event.context else None

        for attempt in range(self.config.max_retries):
            delay = self._calculate_delay(attempt)
            if delay > 0:
                await asyncio.sleep(delay)

            try:
                results = []
                async for event in agent.execute(original_input, context):
                    results.append(event)

                return RecoveryResult(
                    success=True,
                    level_used=self.level,
                    result=results
                )

            except Exception as e:
                if attempt == self.config.max_retries - 1:
                    return RecoveryResult(
                        success=False,
                        level_used=self.level,
                        escalate=True,
                        reason=f"Retry exhausted after {self.config.max_retries} attempts: {e}"
                    )

        return RecoveryResult(
            success=False,
            level_used=self.level,
            escalate=True,
            reason="Retry exhausted"
        )
```

### 4.2 DegradationStrategy

```python
"""Graceful degradation strategy."""

from dataclasses import dataclass, field
from typing import List, Set, Optional


@dataclass
class CapabilityLevel:
    name: str
    features_enabled: Set[str]
    max_complexity: int
    description: str


@dataclass
class DegradationConfig:
    capability_levels: List[CapabilityLevel] = field(default_factory=list)
    min_capability: str = "minimal"
    degradation_timeout: float = 300.0


class DegradationStrategy:
    """Reduce functionality to maintain core operation."""

    def __init__(self, config: DegradationConfig = None):
        self.config = config or DegradationConfig(
            capability_levels=[
                CapabilityLevel(
                    name="full",
                    features_enabled={"search", "analysis", "synthesis", "visualization"},
                    max_complexity=100,
                    description="All features enabled"
                ),
                CapabilityLevel(
                    name="reduced",
                    features_enabled={"search", "analysis"},
                    max_complexity=50,
                    description="Core analysis only"
                ),
                CapabilityLevel(
                    name="minimal",
                    features_enabled={"search"},
                    max_complexity=10,
                    description="Search only"
                ),
            ]
        )
        self._current_level_index = 0

    @property
    def level(self) -> RecoveryLevel:
        return RecoveryLevel.L2_DEGRADATION

    @property
    def current_capability(self) -> CapabilityLevel:
        return self.config.capability_levels[self._current_level_index]

    def can_handle(self, failure_type: FailureType) -> bool:
        return failure_type in (
            FailureType.TIMEOUT,
            FailureType.UNAVAILABLE,
            FailureType.EXCEPTION
        )

    async def recover(
        self,
        failure_event: FailureEvent,
        agent: 'Agent',
        context: 'ExecutionContext'
    ) -> RecoveryResult:
        # Check if we can degrade further
        if self._current_level_index >= len(self.config.capability_levels) - 1:
            return RecoveryResult(
                success=False,
                level_used=self.level,
                escalate=True,
                reason="Already at minimum capability"
            )

        # Degrade to next level
        self._current_level_index += 1
        new_level = self.config.capability_levels[self._current_level_index]

        # Store degradation info in context
        context.set("capability_level", new_level.name)
        context.set("features_enabled", list(new_level.features_enabled))

        return RecoveryResult(
            success=True,
            level_used=self.level,
            result={
                "degraded_to": new_level.name,
                "features": list(new_level.features_enabled),
                "description": new_level.description
            }
        )

    async def restore(self) -> bool:
        if self._current_level_index > 0:
            self._current_level_index -= 1
            return True
        return False
```

---

## V. High-Level Pattern Implementations

### 5.1 FDIRAgent (Complete)

```python
"""Complete FDIR Agent implementation."""

import time
from datetime import datetime
from dataclasses import dataclass, field
from typing import List, AsyncIterator, Any, Optional


@dataclass
class FDIRAgentConfig:
    detectors: List['DetectionStrategy'] = field(default_factory=list)
    isolation_strategy: 'IsolationStrategy' = None
    recovery_strategies: List['RecoveryStrategy'] = field(default_factory=list)
    enable_health_monitoring: bool = True


class FDIRAgent:
    """Complete FDIR pipeline implementation."""

    def __init__(self, agent: 'Agent', config: FDIRAgentConfig = None):
        self._agent = agent
        self.config = config or FDIRAgentConfig()
        self._health_state = HealthState.HEALTHY
        self._failure_count = 0
        self._last_failure: Optional[FailureEvent] = None

        # Initialize defaults
        if not self.config.detectors:
            self.config.detectors = [
                TimeoutDetector(),
                StatisticalAnomalyDetector()
            ]
        if not self.config.isolation_strategy:
            self.config.isolation_strategy = CircuitBreakerIsolation()
        if not self.config.recovery_strategies:
            self.config.recovery_strategies = [
                RetryStrategy(),
                DegradationStrategy()
            ]

        self._escalation_ladder = EscalationLadder(self.config.recovery_strategies)
        self._composite_detector = CompositeDetector(self.config.detectors)

    @property
    def name(self) -> str:
        return f"fdir_{self._agent.name}"

    @property
    def health_state(self) -> HealthState:
        return self._health_state

    async def execute(
        self,
        input: Any,
        context: 'ExecutionContext'
    ) -> AsyncIterator[Any]:
        # Pre-check: Is agent isolated?
        if self._health_state == HealthState.ISOLATED:
            raise CircuitOpenError(
                agent_id=self.name,
                recovery_time=self.config.isolation_strategy.time_until_recovery
            )

        start_time = time.monotonic()
        try:
            # Execute wrapped agent
            results = []
            async for event in self._agent.execute(input, context):
                results.append(event)

            elapsed = time.monotonic() - start_time

            # Detection phase
            observation = {
                "output": results,
                "elapsed": elapsed,
                "exception": None
            }
            detection_result = await self._composite_detector.detect(observation, context)

            if detection_result.is_healthy:
                self._health_state = HealthState.HEALTHY
                self._failure_count = 0
                for result in results:
                    yield result
                return

            # Failure detected - create failure event
            failure_event = FailureEvent(
                failure_type=detection_result.failure_type,
                timestamp=datetime.now(),
                agent_id=self._agent.name,
                message=str(detection_result.evidence),
                context={"input": input, "output": results}
            )

            # Isolation phase
            isolated = await self.config.isolation_strategy.isolate(
                failure_event, self._agent, context
            )
            self._health_state = HealthState.ISOLATED
            self._last_failure = failure_event

            # Recovery phase
            recovery_result = await self._escalation_ladder.recover(
                failure_event, self._agent, context
            )

            if recovery_result.success:
                await self.config.isolation_strategy.release(isolated)
                self._health_state = HealthState.HEALTHY
                if recovery_result.result:
                    for result in recovery_result.result:
                        yield result
            else:
                raise RecoveryExhaustedError(
                    levels_tried=[s.level for s in self.config.recovery_strategies],
                    last_error=recovery_result.reason
                )

        except Exception as e:
            elapsed = time.monotonic() - start_time
            failure_event = FailureEvent(
                failure_type=FailureType.EXCEPTION,
                timestamp=datetime.now(),
                agent_id=self._agent.name,
                message=str(e),
                context={"input": input},
                exception=e
            )

            # Try recovery
            try:
                recovery_result = await self._escalation_ladder.recover(
                    failure_event, self._agent, context
                )
                if recovery_result.success and recovery_result.result:
                    for result in recovery_result.result:
                        yield result
                    return
            except RecoveryExhaustedError:
                pass

            raise
```

---

## VI. End-to-End Workflow Examples

### 6.1 API Reliability Example

```python
"""Complete example: Reliable API agent with FDIR protection."""

import asyncio
from typing import Dict, Any


async def main():
    # Create base agent (simulated API call)
    async def api_call(input: str, context: 'ExecutionContext') -> str:
        # Simulate API with occasional failures
        import random
        if random.random() < 0.3:
            raise TimeoutError("API timeout")
        return f"API response for: {input}"

    base_agent = GenericAdapter(api_call, name="api_agent")

    # Wrap with FDIR protection
    fdir_agent = FDIRAgent(
        agent=base_agent,
        config=FDIRAgentConfig(
            detectors=[
                TimeoutDetector(TimeoutDetectorConfig(timeout_seconds=10.0)),
                StatisticalAnomalyDetector()
            ],
            isolation_strategy=CircuitBreakerIsolation(
                CircuitBreakerConfig(failure_threshold=3)
            ),
            recovery_strategies=[
                RetryStrategy(RetryConfig(max_retries=3)),
                DegradationStrategy()
            ]
        )
    )

    # Create simple context
    context = SimpleContext()

    # Execute with full protection
    try:
        async for result in fdir_agent.execute("test query", context):
            print(f"Result: {result}")
    except RecoveryExhaustedError as e:
        print(f"All recovery failed: {e}")
    except CircuitOpenError as e:
        print(f"Circuit open: {e}")


class SimpleContext:
    """Simple execution context implementation."""

    def __init__(self):
        self._state: Dict[str, Any] = {}
        self._metadata: Dict[str, Any] = {"session_id": "test"}

    @property
    def session_state(self) -> Dict[str, Any]:
        return self._state

    @property
    def metadata(self) -> Dict[str, Any]:
        return self._metadata

    def get(self, key: str, default: Any = None) -> Any:
        return self._state.get(key, default)

    def set(self, key: str, value: Any) -> None:
        self._state[key] = value


if __name__ == "__main__":
    asyncio.run(main())
```

### 6.2 TMR Code Generation Example

```python
"""TMR example: Critical code generation with voting."""

import asyncio


async def main():
    # Create three LLM agents (simulated)
    agents = [
        GenericAdapter(
            lambda i, c: f"def solution_a(): return {hash(i) % 100}",
            name="gpt4"
        ),
        GenericAdapter(
            lambda i, c: f"def solution_a(): return {hash(i) % 100}",
            name="claude"
        ),
        GenericAdapter(
            lambda i, c: f"def solution_b(): return {hash(i) % 100 + 1}",  # Different
            name="gemini"
        ),
    ]

    # TMR with majority voting
    tmr = TMRAgent(
        agents=agents,
        voting_strategy=MajorityVoting(similarity_threshold=0.8)
    )

    context = SimpleContext()

    try:
        async for result in tmr.execute("Write a factorial function", context):
            print(f"Consensus result: {result}")
    except NoConsensusError as e:
        print(f"No consensus: {e.results}")


class TMRAgent:
    """Triple Modular Redundancy Agent."""

    def __init__(self, agents: list, voting_strategy: 'VotingStrategy'):
        self.agents = agents
        self.voting = voting_strategy

    @property
    def name(self) -> str:
        return "tmr_agent"

    async def execute(self, input: Any, context: 'ExecutionContext'):
        # Run all agents in parallel
        tasks = [
            self._run_agent(agent, input, context)
            for agent in self.agents
        ]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Filter successful results
        valid = [r for r in results if not isinstance(r, Exception)]

        if len(valid) < self.voting.min_results_required:
            raise NoConsensusError(results, "Insufficient successful results")

        # Vote
        consensus = self.voting.vote(valid)
        yield consensus

    async def _run_agent(self, agent, input, context):
        results = []
        async for event in agent.execute(input, context):
            results.append(event)
        return results[0] if results else None


if __name__ == "__main__":
    asyncio.run(main())
```

### 6.3 Health-Monitored Pipeline Example

```python
"""Health monitoring example with automatic degradation."""

import asyncio


async def main():
    # Create monitored agent
    base_agent = GenericAdapter(
        lambda i, c: f"Processed: {i}",
        name="processor"
    )

    monitored = HealthMonitorAgent(
        agent=base_agent,
        config=HealthMonitorConfig(
            check_interval=5.0,
            degraded_threshold=0.2,
            failed_threshold=0.5
        )
    )

    # Start health monitoring
    await monitored.start()

    context = SimpleContext()

    # Simulate workload
    for i in range(10):
        try:
            async for result in monitored.execute(f"request_{i}", context):
                print(f"[{monitored.health_state.name}] {result}")
        except Exception as e:
            print(f"Error: {e}")

        print(f"Health: {monitored.health_state.name}, "
              f"Error rate: {monitored.error_rate:.2%}")

        await asyncio.sleep(1)

    await monitored.stop()


class HealthMonitorAgent:
    """Agent with continuous health monitoring."""

    def __init__(self, agent: 'Agent', config: 'HealthMonitorConfig'):
        self._agent = agent
        self.config = config
        self._health_state = HealthState.HEALTHY
        self._success_count = 0
        self._failure_count = 0
        self._running = False
        self._monitor_task = None

    @property
    def name(self) -> str:
        return f"monitored_{self._agent.name}"

    @property
    def health_state(self) -> HealthState:
        return self._health_state

    @property
    def error_rate(self) -> float:
        total = self._success_count + self._failure_count
        return self._failure_count / total if total > 0 else 0.0

    async def start(self):
        self._running = True
        self._monitor_task = asyncio.create_task(self._health_check_loop())

    async def stop(self):
        self._running = False
        if self._monitor_task:
            self._monitor_task.cancel()

    async def _health_check_loop(self):
        while self._running:
            await asyncio.sleep(self.config.check_interval)
            # Update health state based on error rate
            if self.error_rate > self.config.failed_threshold:
                self._health_state = HealthState.FAILED
            elif self.error_rate > self.config.degraded_threshold:
                self._health_state = HealthState.DEGRADED
            else:
                self._health_state = HealthState.HEALTHY

    async def execute(self, input: Any, context: 'ExecutionContext'):
        try:
            async for event in self._agent.execute(input, context):
                yield event
            self._success_count += 1
        except Exception:
            self._failure_count += 1
            raise


if __name__ == "__main__":
    asyncio.run(main())
```

---

## Next Steps

- **Reference**: See [12.7_REFERENCE.md](12.7_REFERENCE.md) for quick lookup and testing examples
