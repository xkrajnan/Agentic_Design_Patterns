# Integration Guide

**Part of**: [Python Architecture for Aerospace Reliability](12.0_OVERVIEW.md)

---

## TL;DR

This document covers framework integration, configuration, metrics, and operational concerns:
- **Adapters**: Connect to Google ADK, LangChain, OpenAI, or any callable
- **Configuration**: Pydantic models with YAML/JSON/env support
- **Metrics**: MTBF, availability calculations, health checks
- **Performance**: Latency overhead, memory footprint, optimization
- **Security**: Input sanitization, credential management, audit logging

---

## I. Framework Adapters

### 1.1 Adapter Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Adapter Protocol                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Framework-Specific Agent                                  │
│          │                                                  │
│          ▼                                                  │
│   ┌─────────────────┐                                       │
│   │    Adapter      │ ◄── Implements Agent Protocol         │
│   │                 │                                       │
│   │ - wrap()        │ ◄── Convert framework agent to Agent  │
│   │ - execute()     │ ◄── Delegate to framework             │
│   │ - name          │ ◄── Expose agent identity             │
│   └─────────────────┘                                       │
│          │                                                  │
│          ▼                                                  │
│   Reliability Patterns (FDIR, TMR, etc.)                    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 GenericAdapter

**Purpose**: Wrap any async callable as an Agent.

```python
class GenericAdapter:
    """Adapt any async callable to Agent protocol."""

    def __init__(
        self,
        func: Callable[[Any, ExecutionContext], Awaitable[Any]],
        name: str = "generic_agent"
    ):
        self._func = func
        self._name = name

    @property
    def name(self) -> str:
        return self._name

    async def execute(
        self,
        input: Any,
        context: ExecutionContext
    ) -> AsyncIterator[Any]:
        result = await self._func(input, context)
        yield result
```

**Usage:**
```python
async def my_function(input: str, context: ExecutionContext) -> str:
    return f"Processed: {input}"

agent = GenericAdapter(my_function, name="my_agent")
```

### 1.3 GoogleADKAdapter

**Purpose**: Wrap Google ADK LlmAgent instances.

```python
class GoogleADKAdapter:
    """Adapt Google ADK LlmAgent to Agent protocol."""

    def __init__(self, adk_agent: 'LlmAgent'):
        self._agent = adk_agent

    @property
    def name(self) -> str:
        return self._agent.name

    async def execute(
        self,
        input: Any,
        context: ExecutionContext
    ) -> AsyncIterator[Any]:
        # Convert context to ADK format
        adk_context = self._convert_context(context)

        # Run through ADK runner
        runner = Runner(
            agent=self._agent,
            app_name="aerospace_reliability"
        )

        session_id = context.metadata.get("session_id", "default")
        async for event in runner.run_async(
            session_id=session_id,
            user_id=context.metadata.get("user_id", "user"),
            new_message=Content(role="user", parts=[Part(text=str(input))])
        ):
            yield self._convert_event(event)
```

### 1.4 LangChainAdapter

**Purpose**: Wrap LangChain chains and agents.

```python
class LangChainAdapter:
    """Adapt LangChain Chain/Agent to Agent protocol."""

    def __init__(
        self,
        chain: Union['Chain', 'AgentExecutor'],
        name: str = "langchain_agent"
    ):
        self._chain = chain
        self._name = name

    @property
    def name(self) -> str:
        return self._name

    async def execute(
        self,
        input: Any,
        context: ExecutionContext
    ) -> AsyncIterator[Any]:
        # Prepare input dict
        if isinstance(input, str):
            input_dict = {"input": input}
        elif isinstance(input, dict):
            input_dict = input
        else:
            input_dict = {"input": str(input)}

        # Add context to input
        input_dict["context"] = dict(context.session_state)

        # Execute chain
        if hasattr(self._chain, 'ainvoke'):
            result = await self._chain.ainvoke(input_dict)
        else:
            result = await asyncio.to_thread(self._chain.invoke, input_dict)

        yield result
```

### 1.5 OpenAIAdapter

**Purpose**: Wrap OpenAI Assistants API.

```python
class OpenAIAdapter:
    """Adapt OpenAI Assistants to Agent protocol."""

    def __init__(
        self,
        assistant_id: str,
        client: 'AsyncOpenAI' = None,
        name: str = None
    ):
        self._assistant_id = assistant_id
        self._client = client or AsyncOpenAI()
        self._name = name or f"openai_{assistant_id[:8]}"

    @property
    def name(self) -> str:
        return self._name

    async def execute(
        self,
        input: Any,
        context: ExecutionContext
    ) -> AsyncIterator[Any]:
        # Get or create thread
        thread_id = context.get("openai_thread_id")
        if not thread_id:
            thread = await self._client.beta.threads.create()
            thread_id = thread.id
            context.set("openai_thread_id", thread_id)

        # Add message
        await self._client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=str(input)
        )

        # Run assistant
        run = await self._client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=self._assistant_id
        )

        # Poll for completion
        while run.status in ["queued", "in_progress"]:
            await asyncio.sleep(0.5)
            run = await self._client.beta.threads.runs.retrieve(
                thread_id=thread_id,
                run_id=run.id
            )

        if run.status == "failed":
            raise RuntimeError(f"Assistant run failed: {run.last_error}")

        # Get messages
        messages = await self._client.beta.threads.messages.list(
            thread_id=thread_id
        )

        # Yield assistant response
        for msg in messages.data:
            if msg.role == "assistant":
                for content in msg.content:
                    if content.type == "text":
                        yield content.text.value
                break
```

---

## II. Configuration System

### 2.1 Pydantic Models

```python
from pydantic import BaseModel, Field
from typing import Optional, List

class DetectionConfig(BaseModel):
    timeout_seconds: float = Field(30.0, ge=0)
    validation_enabled: bool = True
    anomaly_threshold: float = Field(3.0, ge=0)

class IsolationConfig(BaseModel):
    circuit_breaker_enabled: bool = True
    failure_threshold: int = Field(5, ge=1)
    recovery_timeout: float = Field(30.0, ge=0)

class RecoveryConfig(BaseModel):
    max_retries: int = Field(3, ge=0)
    base_delay: float = Field(1.0, ge=0)
    backoff_factor: float = Field(2.0, ge=1)
    fallback_enabled: bool = True

class FDIRConfig(BaseModel):
    """Complete FDIR configuration."""
    detection: DetectionConfig = DetectionConfig()
    isolation: IsolationConfig = IsolationConfig()
    recovery: RecoveryConfig = RecoveryConfig()
    health_monitoring: bool = True
    metrics_enabled: bool = True
```

### 2.2 Configuration Loaders

```python
class ConfigLoader:
    """Load configuration from multiple sources."""

    @staticmethod
    def from_yaml(path: str) -> FDIRConfig:
        with open(path) as f:
            data = yaml.safe_load(f)
        return FDIRConfig(**data)

    @staticmethod
    def from_json(path: str) -> FDIRConfig:
        with open(path) as f:
            data = json.load(f)
        return FDIRConfig(**data)

    @staticmethod
    def from_env(prefix: str = "FDIR_") -> FDIRConfig:
        """Load from environment variables."""
        data = {}
        for key, value in os.environ.items():
            if key.startswith(prefix):
                # Convert FDIR_DETECTION__TIMEOUT_SECONDS to nested dict
                path = key[len(prefix):].lower().split("__")
                _set_nested(data, path, _parse_value(value))
        return FDIRConfig(**data)

    @staticmethod
    def merge(*configs: FDIRConfig) -> FDIRConfig:
        """Merge multiple configs (later overrides earlier)."""
        merged = {}
        for config in configs:
            merged.update(config.dict(exclude_unset=True))
        return FDIRConfig(**merged)
```

### 2.3 Example YAML Configuration

```yaml
# fdir_config.yaml
detection:
  timeout_seconds: 30.0
  validation_enabled: true
  anomaly_threshold: 3.0

isolation:
  circuit_breaker_enabled: true
  failure_threshold: 5
  recovery_timeout: 30.0

recovery:
  max_retries: 3
  base_delay: 1.0
  backoff_factor: 2.0
  fallback_enabled: true

health_monitoring: true
metrics_enabled: true
```

---

## III. Metrics and Monitoring

### 3.1 MTBF Calculator

```python
class MTBFCalculator:
    """Calculate Mean Time Between Failures."""

    def __init__(self, window_size: int = 1000):
        self._success_times: deque = deque(maxlen=window_size)
        self._failure_times: deque = deque(maxlen=window_size)

    def record_success(self, timestamp: float = None):
        self._success_times.append(timestamp or time.time())

    def record_failure(self, timestamp: float = None):
        self._failure_times.append(timestamp or time.time())

    def get_mtbf(self) -> float:
        """Calculate MTBF in seconds."""
        if len(self._failure_times) < 2:
            return float('inf')

        failures = sorted(self._failure_times)
        intervals = [failures[i+1] - failures[i] for i in range(len(failures)-1)]
        return sum(intervals) / len(intervals)

    def get_failure_rate(self) -> float:
        """Calculate failures per hour."""
        total = len(self._success_times) + len(self._failure_times)
        if total == 0:
            return 0.0
        return len(self._failure_times) / total
```

### 3.2 Availability Calculator

```python
class AvailabilityCalculator:
    """Calculate system availability."""

    def __init__(self):
        self._uptime: float = 0.0
        self._downtime: float = 0.0
        self._state_changes: List[Tuple[float, bool]] = []

    def record_state_change(self, is_up: bool, timestamp: float = None):
        timestamp = timestamp or time.time()
        self._state_changes.append((timestamp, is_up))

    def get_availability(self) -> float:
        """
        Calculate availability: A = MTBF / (MTBF + MTTR)
        Simplified: A = uptime / (uptime + downtime)
        """
        if not self._state_changes:
            return 1.0

        uptime = 0.0
        downtime = 0.0
        last_time, last_state = self._state_changes[0]

        for timestamp, is_up in self._state_changes[1:]:
            duration = timestamp - last_time
            if last_state:
                uptime += duration
            else:
                downtime += duration
            last_time, last_state = timestamp, is_up

        total = uptime + downtime
        return uptime / total if total > 0 else 1.0
```

### 3.3 Health Check Implementations

```python
class HealthCheckRunner:
    """Run periodic health checks."""

    def __init__(
        self,
        agents: List[Agent],
        check_interval: float = 60.0,
        check_input: Any = {"health": True}
    ):
        self.agents = agents
        self.check_interval = check_interval
        self.check_input = check_input
        self._results: Dict[str, HealthState] = {}

    async def run(self):
        """Run health checks in background."""
        while True:
            for agent in self.agents:
                try:
                    start = time.monotonic()
                    async for _ in agent.execute(self.check_input, self._context):
                        pass
                    latency = time.monotonic() - start

                    self._results[agent.name] = HealthState.HEALTHY
                    self._metrics.record_latency(agent.name, latency)

                except Exception as e:
                    self._results[agent.name] = HealthState.FAILED
                    self._metrics.record_failure(agent.name, e)

            await asyncio.sleep(self.check_interval)

    def get_status(self) -> Dict[str, HealthState]:
        return dict(self._results)
```

---

## IV. Performance Considerations

### 4.1 Latency Overhead Analysis

| Component | Typical Overhead | Notes |
|-----------|-----------------|-------|
| Detection (composite) | 1-5ms | Runs after execution |
| Circuit Breaker Check | < 1ms | State lookup only |
| Retry Logic | 0ms (success path) | Only on failure |
| TMR Parallel | +10-50ms | Concurrent execution |
| Health Monitoring | 0ms (async) | Background task |

**Total FDIR Overhead (success path):** 2-10ms

### 4.2 Memory Footprint

| Component | Memory Usage | Scaling Factor |
|-----------|--------------|----------------|
| Metrics History | ~1KB per agent | × window_size |
| Circuit Breaker State | ~100B per agent | Constant |
| Health Monitor | ~2KB per agent | × metrics tracked |
| Session State | Variable | × active sessions |

**Recommendation:** For 100 agents with default settings: ~500KB total overhead

### 4.3 Throughput Implications

**TMR/NMR:**
- 3× LLM calls for TMR
- Consider cost vs reliability tradeoff
- Batch requests where possible

**Retry:**
- Worst case: max_retries × base_latency
- Use exponential backoff to reduce load

### 4.4 Optimization Strategies

| Strategy | Description | Impact |
|----------|-------------|--------|
| Lazy Detection | Only run expensive detectors on failure | -3ms success path |
| Async Metrics | Don't block on metric recording | -1ms |
| Connection Pooling | Reuse HTTP connections | -50ms+ per request |
| Caching | Cache health check results | -100ms |
| Circuit Breaker Precheck | Check before expensive operations | Prevents wasted calls |

---

## V. Security Considerations

### 5.1 Input Sanitization

```python
class InputSanitizer:
    """Sanitize agent inputs to prevent injection attacks."""

    def __init__(
        self,
        max_length: int = 10000,
        blocked_patterns: List[str] = None,
        encoding: str = "utf-8"
    ):
        self.max_length = max_length
        self.blocked_patterns = blocked_patterns or []

    def sanitize(self, input: Any) -> Any:
        if isinstance(input, str):
            # Length limit
            if len(input) > self.max_length:
                raise ValueError(f"Input exceeds max length: {self.max_length}")

            # Pattern blocking
            for pattern in self.blocked_patterns:
                if re.search(pattern, input, re.IGNORECASE):
                    raise ValueError(f"Blocked pattern detected: {pattern}")

            # Encoding validation
            input.encode(self.encoding)

        elif isinstance(input, dict):
            return {k: self.sanitize(v) for k, v in input.items()}

        return input
```

### 5.2 Credential Management

```python
class CredentialManager:
    """Secure credential management for multi-provider setups."""

    def __init__(self, vault_client: Optional['VaultClient'] = None):
        self._vault = vault_client
        self._cache: Dict[str, str] = {}
        self._cache_ttl: Dict[str, float] = {}

    async def get_api_key(self, provider: str) -> str:
        # Check cache
        if provider in self._cache:
            if time.time() < self._cache_ttl.get(provider, 0):
                return self._cache[provider]

        # Get from vault or environment
        if self._vault:
            key = await self._vault.read_secret(f"api_keys/{provider}")
        else:
            key = os.environ.get(f"{provider.upper()}_API_KEY")

        if not key:
            raise ConfigurationError(f"No API key for provider: {provider}")

        # Cache with TTL
        self._cache[provider] = key
        self._cache_ttl[provider] = time.time() + 300  # 5 min TTL

        return key

    def rotate_credential(self, provider: str):
        """Force credential refresh."""
        self._cache.pop(provider, None)
        self._cache_ttl.pop(provider, None)
```

### 5.3 Rate Limiting

```python
class RateLimiter:
    """Token bucket rate limiter."""

    def __init__(
        self,
        rate: float,          # Tokens per second
        capacity: float,      # Max tokens
        per_agent: bool = True
    ):
        self.rate = rate
        self.capacity = capacity
        self.per_agent = per_agent
        self._buckets: Dict[str, float] = {}
        self._last_update: Dict[str, float] = {}

    async def acquire(self, agent_id: str = "global") -> bool:
        key = agent_id if self.per_agent else "global"
        now = time.time()

        # Initialize or refill bucket
        if key not in self._buckets:
            self._buckets[key] = self.capacity
            self._last_update[key] = now
        else:
            elapsed = now - self._last_update[key]
            self._buckets[key] = min(
                self.capacity,
                self._buckets[key] + elapsed * self.rate
            )
            self._last_update[key] = now

        # Try to consume token
        if self._buckets[key] >= 1.0:
            self._buckets[key] -= 1.0
            return True
        return False

    async def wait_for_token(self, agent_id: str = "global"):
        while not await self.acquire(agent_id):
            await asyncio.sleep(0.1)
```

### 5.4 Audit Logging

```python
class AuditLogger:
    """Audit logging for FDIR events."""

    def __init__(self, logger: logging.Logger = None):
        self.logger = logger or logging.getLogger("aerospace_reliability.audit")

    def log_execution(
        self,
        agent_id: str,
        input_hash: str,
        success: bool,
        latency: float,
        context: Dict[str, Any]
    ):
        self.logger.info(
            "EXECUTION",
            extra={
                "agent_id": agent_id,
                "input_hash": input_hash,
                "success": success,
                "latency_ms": latency * 1000,
                "user_id": context.get("user_id"),
                "session_id": context.get("session_id"),
                "timestamp": datetime.utcnow().isoformat()
            }
        )

    def log_failure(
        self,
        agent_id: str,
        failure_type: FailureType,
        recovery_level: RecoveryLevel,
        context: Dict[str, Any]
    ):
        self.logger.warning(
            "FAILURE",
            extra={
                "agent_id": agent_id,
                "failure_type": failure_type.name,
                "recovery_level": recovery_level.name,
                "user_id": context.get("user_id"),
                "timestamp": datetime.utcnow().isoformat()
            }
        )

    def log_isolation(
        self,
        agent_id: str,
        reason: str,
        duration: float
    ):
        self.logger.error(
            "ISOLATION",
            extra={
                "agent_id": agent_id,
                "reason": reason,
                "expected_duration_s": duration,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
```

---

## VI. Checklist Pattern Integration

The aerospace checklist methodology maps naturally to FDIR:

| Checklist Type | FDIR Phase | Implementation |
|---------------|------------|----------------|
| Pre-flight | Pre-execution | `CompositeDetector` with validators |
| In-flight | During execution | `HealthMonitor` background checks |
| Post-flight | Post-execution | `OutputValidationDetector` |
| Emergency | On failure | `EscalationLadder` recovery |

### Integration Points

```python
class ChecklistRunner:
    """Run pre/post execution checklists."""

    def __init__(
        self,
        pre_checks: List[DetectionStrategy],
        post_checks: List[DetectionStrategy]
    ):
        self.pre_detector = CompositeDetector(pre_checks, fail_fast=True)
        self.post_detector = CompositeDetector(post_checks, fail_fast=False)

    async def run_pre_checks(self, context: ExecutionContext) -> DetectionResult:
        return await self.pre_detector.detect({"phase": "pre"}, context)

    async def run_post_checks(
        self,
        output: Any,
        context: ExecutionContext
    ) -> DetectionResult:
        return await self.post_detector.detect({"output": output}, context)
```

---

## Next Steps

- **Code**: See [12.6_EXAMPLES.md](12.6_EXAMPLES.md) for complete implementations
- **Reference**: See [12.7_REFERENCE.md](12.7_REFERENCE.md) for quick lookup
